{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "params = [[150, 0.95], [200, 0.95], [300, 0.85], [400, 0.6], [500, 0.6], [1000, 0.4], [1500, 0.4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ОБЩИЕ ФУНКЦИИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_search(degrees, graph): #Жадный поиск\n",
    "    candidates = list(degrees.keys())\n",
    "    clique = [candidates[0]]\n",
    "\n",
    "    while True:\n",
    "        candidate_index = 0 \n",
    "        to_drop = []\n",
    "\n",
    "        for candidate in candidates: #Перестроение списка кандидатов\n",
    "            for vertex in clique:\n",
    "                if graph[vertex][candidate] == 0 or vertex == candidate:\n",
    "                    to_drop.append(candidate_index)\n",
    "                    break\n",
    "                \n",
    "            candidate_index += 1\n",
    "\n",
    "        candidates = [i for j, i in enumerate(candidates) if j not in to_drop]\n",
    "        \n",
    "        if len(candidates) == 0: #Если кандидаты ещё есть - добавление в клику лучшего, иначе завершение программы\n",
    "            break\n",
    "        clique.append(candidates[0])\n",
    "\n",
    "    return clique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_degrees_in_sets(set1, set2, graph):\n",
    "    degrees = {}\n",
    "    for i in range(len(set1)):\n",
    "        degree = 0\n",
    "        for j in range(len(set2)):\n",
    "            if set1[i] != set2[j] and graph[set1[i]][set2[j]] == 1.0:\n",
    "                degree += 1\n",
    "\n",
    "        degrees[set1[i]] = degree\n",
    "\n",
    "    degrees = {k: v for k, v in sorted(degrees.items(), key=lambda item: item[1], reverse = True)}\n",
    "\n",
    "    return degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_lists(graph): # Преобразование графа в список и получение списков смежности и степеней для вершин\n",
    "    graph = list(graph)\n",
    "    for i in range(len(graph)):\n",
    "        graph[i] = list(graph[i])\n",
    "\n",
    "    adj_list = {}\n",
    "    degrees = {}\n",
    "    for i in range(len(graph)):\n",
    "        temp = []\n",
    "        degree = 0\n",
    "        for j in range(len(graph)):\n",
    "            if graph[i][j] == 1.0:\n",
    "                degree += 1\n",
    "                temp.append(j)\n",
    "        adj_list[i] = temp\n",
    "        degrees[i] = degree\n",
    "\n",
    "    degrees = {k: v for k, v in sorted(degrees.items(), key=lambda item: item[1], reverse = True)}\n",
    "    return graph, degrees, adj_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВСПОМОГАТЕЛЬНЫЕ ФУНКЦИИ АЛГОРИТМОВ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_clique(graph, set):\n",
    "    for i in range(len(set)):\n",
    "        for j in range(i, len(set)):\n",
    "            if graph[i][j] == 0:\n",
    "                return False\n",
    "            \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_num_edges(set, graph):\n",
    "    edges_num = 0\n",
    "    vertex_num = len(set)\n",
    "    \n",
    "    for i in range(vertex_num):\n",
    "        for j in range(i, vertex_num):\n",
    "            if graph[set[i]][set[j]] > 0:\n",
    "                edges_num += 1\n",
    "\n",
    "    return edges_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebuild_candidates(candidates, clique, graph):\n",
    "    candidate_index = 0 \n",
    "    to_drop = []\n",
    "\n",
    "    #print(clique, candidates)\n",
    "\n",
    "    for candidate in candidates: #Перестроение списка кандидатов\n",
    "        for vertex in clique:\n",
    "            #print(vertex, candidate)\n",
    "            if vertex == candidate or graph[vertex][candidate] == 0:\n",
    "                to_drop.append(candidate_index)\n",
    "                break\n",
    "            \n",
    "        candidate_index += 1\n",
    "\n",
    "    candidates = [i for j, i in enumerate(candidates) if j not in to_drop]\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_quality(current, qualityes):\n",
    "    best = current\n",
    "    for i in range(len(qualityes)):\n",
    "        if qualityes[i][2] > best:\n",
    "            best = qualityes[i]\n",
    "\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def legal_neighbourhood(clique, vertices, graph, taboo_list):\n",
    "    qualityes = []\n",
    "\n",
    "    for i in range(len(clique)):\n",
    "        temp_clique = [k for k in clique if k != clique[i]] #clique.pop(i)\n",
    "        temp_candidates = rebuild_candidates(vertices, temp_clique, graph)\n",
    "        temp_num_candidates = len(temp_candidates)\n",
    "        for j in range(temp_num_candidates):\n",
    "            if taboo_list[temp_candidates[i]] == 0: \n",
    "                qualityes.append([i, j, len(rebuild_candidates(temp_candidates, temp_clique.append(temp_candidates[j], graph)))])\n",
    "    \n",
    "    return qualityes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def starting_solution(graph, degrees, adj_list, clique_size):\n",
    "    vertices = list(adj_list.keys())\n",
    "    clique = greedy_search(degrees, graph)\n",
    "    not_clique = [i for i in vertices if i not in clique]\n",
    "    while len(clique) < clique_size:\n",
    "        clique.append(not_clique[random.randint(0, len(not_clique) - 1)])\n",
    "    return clique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_opt_neighbourhood(graph, taboo_list, minInClique, maxOutClique, minIn, maxOut):\n",
    "    T = []\n",
    "\n",
    "    minInClique_list = list(minInClique.keys())\n",
    "    maxOutClique_list = list(maxOutClique.keys())\n",
    "\n",
    "    for i in range(len(minInClique)):\n",
    "        for j in range(len(maxOutClique)):\n",
    "            if taboo_list[minInClique_list[i]] == 0: \n",
    "                delta = int(graph[minInClique_list[i]][maxOutClique_list[j]])\n",
    "                if delta == 0:\n",
    "                    T.append([minInClique_list[i], maxOutClique_list[j], maxOut - minIn - int(graph[minInClique_list[i]][maxOutClique_list[j]])])\n",
    "\n",
    "    if len(T) > 0:\n",
    "        return(T[random.randint(0, len(T) - 1)])\n",
    "    else:\n",
    "        if len(minInClique_list) < 1 or len(maxOutClique_list) < 1:\n",
    "            print(maxOut, maxOutClique_list, minIn, minInClique_list)\n",
    "        if len(minInClique_list) == 1:\n",
    "            u = minInClique_list[0]\n",
    "        else:\n",
    "            u = minInClique_list[random.randint(0, len(minInClique_list) - 1)]\n",
    "\n",
    "        if len(maxOutClique_list) == 1:\n",
    "            v = maxOutClique_list[0]\n",
    "        else:\n",
    "            v = maxOutClique_list[random.randint(0, len(maxOutClique_list) - 1)]\n",
    "        return([u, v, maxOut - minIn])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "АЛГОРИТМЫ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AMTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TS_AMTS(graph, adj_list, clique, clique_size, search_depth, iterations, movements, graph_params):\n",
    "    goal_number = int(clique_size * (clique_size - 1) / 2)\n",
    "    num_vertices = len(graph)\n",
    "    It = 0\n",
    "    best_clique = clique\n",
    "    best_num_edges = set_num_edges(clique, graph)\n",
    "    taboo_list = [0] * num_vertices\n",
    "    vertices = list(adj_list.keys())\n",
    "    num_edges = best_num_edges\n",
    "    quality = []\n",
    "    v, u = 0, 0\n",
    "\n",
    "    while It < search_depth:\n",
    "        #print(\"Taboo\", clique, num_edges)\n",
    "\n",
    "        not_clique = [i for i in vertices if i not in clique]\n",
    "        local_degrees = calculate_degrees_in_sets(clique, clique, graph)\n",
    "        outer_degrees = calculate_degrees_in_sets(not_clique, clique, graph)\n",
    "\n",
    "        minIn = list(local_degrees.values())[-1]\n",
    "        #print(\"Min In\", minIn, local_degrees)\n",
    "        maxOut = list(outer_degrees.values())[0]\n",
    "        #print(\"Max Out\", maxOut, outer_degrees)\n",
    "\n",
    "        minInClique = {k: v for k, v in sorted(local_degrees.items(), key=lambda item: item[1], reverse = True) if v == minIn and taboo_list[k] == 0}\n",
    "        maxOutClique = {k: v for k, v in sorted(outer_degrees.items(), key=lambda item: item[1], reverse = True) if v == maxOut and taboo_list[k] == 0}\n",
    "        #minInClique = [k for k, v in local_degrees if (v == minIn and k not in taboo_list)] \n",
    "        #maxOutClique = [k for k, v in outer_degrees if (v == maxOut and k not in taboo_list)] \n",
    "        #print(\"Taboo list\", taboo_list)\n",
    "        if len(minInClique) == 0:\n",
    "            minInClique = {k: v for k, v in sorted(local_degrees.items(), key=lambda item: item[1], reverse = True) if v == minIn}    \n",
    "        if len(maxOutClique) == 0:\n",
    "            maxOutClique = {k: v for k, v in sorted(outer_degrees.items(), key=lambda item: item[1], reverse = True) if v == maxOut}\n",
    "\n",
    "        quality = k_opt_neighbourhood(graph, taboo_list, minInClique, maxOutClique, minIn, maxOut)\n",
    "        \n",
    "        if quality[2] != num_edges:\n",
    "            new_clique = [k for k in clique if k != quality[0]] #clique.pop(clique.index(quality[0]))\n",
    "            new_clique.append(quality[1])\n",
    "            new_num_edges = quality[2]\n",
    "        else:\n",
    "            P = min([(goal_number - quality[2] + 2) / len(vertices), 0.1])\n",
    "            if random.random() > P:\n",
    "\n",
    "                u = quality[0]\n",
    "                v = quality[1]\n",
    "                new_clique = [k for k in clique if k != u] #clique.pop(u)\n",
    "\n",
    "                new_clique.append(v)\n",
    "                new_num_edges = quality[2]\n",
    "            else:\n",
    "                u = clique[random.randint(0, len(clique) - 1)]\n",
    "                worseInClique = {k : v for k, v in outer_degrees.items() if v < clique_size * graph_params[2]}\n",
    "                \n",
    "                if len(worseInClique) == 0:\n",
    "                    mulitiplyer = 2\n",
    "                    while len(worseInClique) == 0:\n",
    "                        worseInClique = {k : v for k, v in outer_degrees.items() if v < clique_size * graph_params[2] * mulitiplyer}\n",
    "                        mulitiplyer += 1\n",
    "\n",
    "                if len(worseInClique) > 1:\n",
    "                    v = not_clique[list(worseInClique.values())[random.randint(0, len(worseInClique) - 1)]]\n",
    "                else:\n",
    "                    #print(worseInClique)\n",
    "                    v = list(worseInClique.values())[0]\n",
    "                new_clique = [k for k in clique if k != u] #clique.pop(u)\n",
    "\n",
    "                new_clique.append(v)\n",
    "                new_num_edges = set_num_edges(clique, graph)\n",
    "        \n",
    "        #print(clique, new_clique)\n",
    "\n",
    "        movements[v] += 1\n",
    "        movements[u] += 1\n",
    "\n",
    "        IsOk = True\n",
    "        for counter in range(len(movements)):\n",
    "            if movements[counter] > clique_size:\n",
    "                IsOk = False\n",
    "            else:\n",
    "                IsOk = True\n",
    "                break\n",
    "        if IsOk == False:\n",
    "            movements = [0] * len(graph)\n",
    "\n",
    "        #if len(clique) > clique_size:\n",
    "            #print(\"ACHTUNG\",clique_size, clique, num_edges, goal_number)\n",
    "            #pass\n",
    "\n",
    "        if new_num_edges == goal_number:\n",
    "            #print(\"Taboo complete\", new_clique, new_num_edges, \"iterations\", iterations, It)\n",
    "            return new_clique, movements\n",
    "\n",
    "        clique = new_clique\n",
    "        num_edges = new_num_edges\n",
    "        \n",
    "        iterations += 1\n",
    "\n",
    "        if new_num_edges > best_num_edges:\n",
    "            best_clique = new_clique\n",
    "            best_num_edges = new_num_edges\n",
    "            It = 0\n",
    "        else:\n",
    "            It += 1 \n",
    "\n",
    "        for i in range(num_vertices):\n",
    "            if taboo_list[i] > 0:\n",
    "                taboo_list[i] -= 1\n",
    "        l1 = clique_size - num_edges\n",
    "        l = min([l1, 10])\n",
    "        C = max(clique_size / 40, 6)\n",
    "        taboo_list[u] = int(l + random.randint(0, int(C)))\n",
    "        taboo_list[v] = int(0.6 * l + random.randint(0, int(0.6 * C))) + 1\n",
    "\n",
    "        #print(clique)\n",
    "\n",
    "    #print(\"Taboo best\", best_clique, best_num_edges)\n",
    "    return best_clique, movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AMTS(degrees, graph, adj_list, clique_size, search_depth, max_iters, graph_params):\n",
    "    clique = starting_solution(graph, degrees, adj_list, clique_size)\n",
    "    iterations = 0\n",
    "    movements = [0] * len(graph)\n",
    "    vertices = [i for i in range(len(graph))]\n",
    "\n",
    "    while iterations < max_iters:\n",
    "        clique, movements = TS_AMTS(graph, adj_list, clique, clique_size, search_depth, iterations, movements, graph_params)\n",
    "        #print(\"AMTS\", clique, set_num_edges(clique, graph))\n",
    "        if is_clique(graph, clique):\n",
    "            return clique\n",
    "        if set_num_edges(clique, graph) == int(clique_size * (clique_size - 1) / 2):\n",
    "            return clique\n",
    "        else:\n",
    "            \n",
    "            minMovementsVal = min(movements)\n",
    "            minMovementsInd = [i for i in range(len(graph)) if movements[i] == minMovementsVal]\n",
    "            clique = [minMovementsInd[random.randint(0, len(minMovementsInd) - 1)]]\n",
    "            while len(clique) < clique_size:\n",
    "                not_clique = [i for i in vertices if i not in clique]\n",
    "                restart_candidates = calculate_degrees_in_sets(not_clique, clique, graph)\n",
    "                max_restart_degree = max(list(restart_candidates.values()))\n",
    "                mxdeg_restart_candidates = {k : movements[k] for k in restart_candidates.keys() if restart_candidates[k] == max_restart_degree}\n",
    "                #print(clique, clique_size, mxdeg_restart_candidates)\n",
    "                if len(mxdeg_restart_candidates) == 1:\n",
    "                    v = list(mxdeg_restart_candidates.keys())[0]\n",
    "                else:\n",
    "                    min_movements = min(list(mxdeg_restart_candidates.values()))\n",
    "                    final_candidates = [i for i in list(mxdeg_restart_candidates.keys()) if mxdeg_restart_candidates[i] == min_movements]\n",
    "                    #print(final_candidates)\n",
    "                    if len(final_candidates) == 1:\n",
    "                        v = final_candidates[0]\n",
    "                    else:\n",
    "                        v = final_candidates[random.randint(0, len(final_candidates) - 1)]\n",
    "                clique.append(v)\n",
    "\n",
    "        #print(\"AMTS\", clique, set_num_edges(clique, graph))\n",
    "\n",
    "        iterations += 1\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_AMTS(graph, graph_params, degrees, adj_list, max_iterations):\n",
    "    start_time = time.time()\n",
    "    end_time = start_time + 50\n",
    "    clique = []\n",
    "    for i in range(int(graph_params[-2]), int(graph_params[-1])):\n",
    "        sampe = AMTS(degrees, graph, adj_list, i, 50, max_iterations, graph_params)\n",
    "        #AMTS(degrees, graph, adj_list, clique_size, search_depth, max_iters, graph_params)\n",
    "        #print(sampe)\n",
    "        if sampe == None:\n",
    "            i -= 1\n",
    "            break\n",
    "        else:\n",
    "            clique = sampe\n",
    "            end_time = time.time()\n",
    "\n",
    "    return len(clique), end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sets_intersection(set1, set2):\n",
    "    common = []\n",
    "    for vertex in set1:\n",
    "        if vertex in set2:\n",
    "            common.append(vertex)\n",
    "    \n",
    "    return common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SelectMinPenalties(penalties, set):\n",
    "    set_penalties = {}\n",
    "    for i in range(len(set)):\n",
    "        set_penalties[set[i]] = penalties[set[i]]\n",
    "    \n",
    "    min_set_penalties = {k: v for k, v in set_penalties.items() if v == min(list(set_penalties.values()))}\n",
    "    #print(min_set_penalties, len(min_set_penalties), random.randint(0, len(min_set_penalties) - 1))\n",
    "    return list(min_set_penalties.keys())[random.randint(0, len(min_set_penalties) - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DropNonAdjacentToV(clique, vertex, graph):\n",
    "    to_drop = []\n",
    "    for i in range(len(clique)):\n",
    "        if clique[i] != vertex:\n",
    "            #print(clique, clique[i], vertex)\n",
    "            if graph[vertex][clique[i]] == 0:\n",
    "                to_drop.append(clique[i])\n",
    "    clique = [i for i in clique if i not in to_drop]\n",
    "    return clique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebuild_level_neighbourhood(clique, graph, vertices, used):\n",
    "    temp_candidates = []\n",
    "    new_candidates = []\n",
    "    #print(len(clique), len(temp_candidates))\n",
    "    for i in range(len(clique)):\n",
    "        temp_clique = [k for k in clique if k != clique[i]] #clique.pop(i)\n",
    "        #print(\"temp clique\", temp_clique)\n",
    "        if len(temp_clique) > 0:\n",
    "            temp = rebuild_candidates(vertices, temp_clique, graph)\n",
    "            temp_candidates.append([k for k in temp if k not in clique and k not in used])\n",
    "\n",
    "    for i in range(len(temp_candidates)):\n",
    "        #print(temp_candidates[i])\n",
    "        for j in range(len(temp_candidates[i])):\n",
    "            if temp_candidates[i][j] not in new_candidates:\n",
    "                new_candidates.append(temp_candidates[i][j])\n",
    "        \n",
    "    return new_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DLS_expand(graph, clique, penalties, iterations, vertices):\n",
    "    candidates = rebuild_candidates(vertices, clique, graph)\n",
    "    v = None\n",
    "    while len(candidates) > 0:\n",
    "        v = SelectMinPenalties(penalties, candidates)\n",
    "        clique.append(v)\n",
    "        iterations += 1\n",
    "        #print(\"expand\", clique)\n",
    "        #print(candidates, \"\\n\")\n",
    "        candidates = rebuild_candidates(vertices, clique, graph)\n",
    "    \n",
    "    return clique, v, iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DLS_PlateauSearch(graph, clique, recorded_clique, vertices, penalties, iterations, max_iters):\n",
    "    candidates = rebuild_candidates(vertices, clique, graph)\n",
    "    intersection = sets_intersection(clique, recorded_clique)\n",
    "    level_candidates = rebuild_level_neighbourhood(clique, graph, vertices, used = [])\n",
    "\n",
    "    used = []\n",
    "    v = None\n",
    "    #print(\"plateau\")\n",
    "    while len(candidates) == 0 and len(level_candidates) != 0 and len(intersection) != 0:\n",
    "        #if iterations >= max_iters:\n",
    "            #break\n",
    "        #print(\"level\", level_candidates)\n",
    "        v = SelectMinPenalties(penalties, level_candidates)\n",
    "        #penalties[v] += 5\n",
    "        #print(v)\n",
    "        used.append(v)\n",
    "        clique.append(v)\n",
    "        clique = DropNonAdjacentToV(clique, v, graph)\n",
    "\n",
    "        #print(clique)\n",
    "        \n",
    "        #print(\"plateau\", clique)\n",
    "        candidates = rebuild_candidates(vertices, clique, graph)\n",
    "        intersection = sets_intersection(clique, recorded_clique)\n",
    "        level_candidates = rebuild_level_neighbourhood(clique, graph, vertices, used)\n",
    "        iterations += 1\n",
    "\n",
    "    return clique, v, iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DLS(graph, clique_size, penalty_delay, max_iters):\n",
    "    vertices = [i for i in range(len(graph))]\n",
    "    v = 0\n",
    "    iterations = 0\n",
    "    clique = [random.randint(0, len(graph) - 1)]\n",
    "    penalties = [0] * len(graph)\n",
    "    candidates = rebuild_candidates(vertices, clique, graph)\n",
    "\n",
    "    while iterations < max_iters:\n",
    "        clique, v, iterations = DLS_expand(graph, clique, penalties, iterations, vertices)\n",
    "\n",
    "        if len(clique) == clique_size:\n",
    "            return clique\n",
    "        recorded_clique = clique\n",
    "        clique, v, iterations = DLS_PlateauSearch(graph, clique, recorded_clique, vertices, penalties, iterations, max_iters)\n",
    "        #print(clique, recorded_clique)\n",
    "        candidates = rebuild_candidates(vertices, clique, graph)\n",
    "\n",
    "        #print(\"DLS\", clique)\n",
    "\n",
    "        while len(candidates) > 0:\n",
    "            #print(\"Were candidates\")\n",
    "            clique, v, iterations = DLS_expand(graph, clique, penalties, iterations, vertices)\n",
    "            if len(clique) == clique_size:\n",
    "                return clique\n",
    "            clique, v, iterations = DLS_PlateauSearch(graph, clique, recorded_clique, vertices, penalties, iterations, max_iters)\n",
    "            candidates = rebuild_candidates(vertices, clique, graph)\n",
    "    \n",
    "        for i in range(len(penalties)):\n",
    "            if penalties[i] > 0:\n",
    "                penalties[i] -= 1\n",
    "            if v != None:\n",
    "                penalties[v] = penalty_delay\n",
    "\n",
    "        if penalty_delay > 1 and v != None:\n",
    "            clique = [v]\n",
    "        else:\n",
    "            not_clique = [i for i in vertices if i not in clique]\n",
    "            v = not_clique[random.randint(0, len(not_clique) - 1)]\n",
    "            clique.append(v)\n",
    "            clique = DropNonAdjacentToV(clique, v, graph)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_DLS(graph, graph_params, degrees, adj_list, max_iterations):\n",
    "    start_time = time.time()\n",
    "    end_time = start_time + 50\n",
    "    clique = []\n",
    "    for i in range(int(graph_params[-2]), int(graph_params[-1])):\n",
    "        sampe = DLS(graph, i, 2, max_iterations)\n",
    "        #AMTS(degrees, graph, adj_list, clique_size, search_depth, max_iters, graph_params)\n",
    "        #print(sampe)\n",
    "        if sampe == None:\n",
    "            i -= 1\n",
    "            break\n",
    "        else:\n",
    "            clique = sampe\n",
    "            end_time = time.time()\n",
    "            #print(clique, \"\\n\")\n",
    "            #for vertex in clique:\n",
    "                #print(vertex, adj_list[vertex])\n",
    "    return len(clique), end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PLS_penalties(graph, clique, selections, max_selections, iterations, vertices, clique_size, penalties):\n",
    "    used = []\n",
    "    candidates = rebuild_candidates(vertices, [], graph)\n",
    "    level_candidates = rebuild_level_neighbourhood(clique, graph, vertices, used)\n",
    "    \n",
    "    while iterations > 0 and selections < max_selections:\n",
    "        while len(candidates) > 0 or len(level_candidates) > 0:\n",
    "            candidates = rebuild_candidates(vertices, clique, graph)\n",
    "            while len(candidates) > 0:\n",
    "                #print(candidates)\n",
    "                candidates = rebuild_candidates(vertices, clique, graph)\n",
    "                candidate_penalties = {k : penalties[k] for k in candidates}\n",
    "                #print(candidates, candidate_penalties)\n",
    "                min_penalties = min(list(candidate_penalties.values()))\n",
    "                min_pen_candidates = [i for i in candidates if penalties[i] == min_penalties]\n",
    "\n",
    "                #print(candidates, min_pen_candidates)\n",
    "                if len(min_pen_candidates) == 1:\n",
    "                    v = min_pen_candidates[0]\n",
    "                else:\n",
    "                    v = min_pen_candidates[random.randint(0, len(min_pen_candidates) - 1)]\n",
    "                clique.append(v)\n",
    "                candidates = rebuild_candidates(vertices, clique, graph)\n",
    "\n",
    "            if len(clique) == clique_size:\n",
    "                return clique, selections#, penalties\n",
    "            selections += 1\n",
    "            #candidates = rebuild_candidates(vertices, [], graph)\n",
    "            level_candidates = rebuild_level_neighbourhood(clique, graph, vertices, used)\n",
    "            if len(level_candidates) > 0:\n",
    "                candidate_penalties = {k : penalties[k] for k in level_candidates}\n",
    "                min_penalties = min(list(candidate_penalties.values()))\n",
    "                min_pen_candidates = [i for i in level_candidates if penalties[i] == min_penalties]\n",
    "\n",
    "                #print(level_candidates, min_pen_candidates)\n",
    "                if len(min_pen_candidates) == 1:\n",
    "                    v = min_pen_candidates[0]\n",
    "                else:\n",
    "                    v = min_pen_candidates[random.randint(0, len(min_pen_candidates) - 1)]\n",
    "                clique.append(v)\n",
    "                clique = DropNonAdjacentToV(clique, v, graph)\n",
    "                used.append(v)\n",
    "        iterations -= 1\n",
    "        for i in range(len(penalties)):\n",
    "            if penalties[i] == 0:\n",
    "                penalties[i] -= 1\n",
    "            if i in used:\n",
    "                penalties[i] += 1\n",
    "        not_clique = [i for i in vertices if i not in clique]\n",
    "        u = not_clique[random.randint(0, len(not_clique) - 1)]\n",
    "        clique.append(u)\n",
    "        clique = DropNonAdjacentToV(clique, u, graph)\n",
    "    return clique, selections#, penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PLS_degrees(graph, clique, degrees, selections, max_selections, iterations, vertices, clique_size, penalties):\n",
    "    used = []\n",
    "    candidates = rebuild_candidates(vertices, [], graph)\n",
    "    level_candidates = rebuild_level_neighbourhood(clique, graph, vertices, used)\n",
    "\n",
    "    while iterations > 0 and selections < max_selections:\n",
    "        while len(candidates) > 0 or len(level_candidates) > 0:\n",
    "            candidates = rebuild_candidates(vertices, clique, graph)\n",
    "            while len(candidates) > 0:\n",
    "                candidates = rebuild_candidates(vertices, clique, graph)\n",
    "                cand_degrees = {k : v for k, v in degrees.items() if k in candidates}\n",
    "                #print(candidates, cand_degrees)\n",
    "                max_deg = max(list(cand_degrees.values()))\n",
    "                max_deg_candidates = [i for i in list(cand_degrees.keys()) if cand_degrees[i] == max_deg]\n",
    "\n",
    "                if len(max_deg_candidates) == 1:\n",
    "                    v = max_deg_candidates[0]\n",
    "                else:\n",
    "                    v = max_deg_candidates[random.randint(0, len(max_deg_candidates) - 1)]\n",
    "                clique.append(v)\n",
    "                #used.append(v)\n",
    "                #print(\"expansion\", clique, level_candidates, max_deg_candidates)\n",
    "                candidates = rebuild_candidates(vertices, clique, graph)\n",
    "                #print(candidates)\n",
    "\n",
    "            if len(clique) == clique_size:\n",
    "                return clique, selections#, penalties\n",
    "            selections += 1\n",
    "                #candidates = rebuild_candidates(vertices, [], graph)\n",
    "            level_candidates = rebuild_level_neighbourhood(clique, graph, vertices, used)\n",
    "            if len(level_candidates) > 0:\n",
    "                level_cand_degrees = {k : v for k, v in degrees.items() if k in level_candidates}\n",
    "                max_deg = max(list(level_cand_degrees.values()))\n",
    "                max_deg_candidates = [i for i in list(level_cand_degrees.keys()) if level_cand_degrees[i] == max_deg]\n",
    "\n",
    "                if len(max_deg_candidates) == 1:\n",
    "                    v = max_deg_candidates[0]\n",
    "                else:\n",
    "                    v = max_deg_candidates[random.randint(0, len(max_deg_candidates) - 1)]\n",
    "                clique.append(v)\n",
    "                clique = DropNonAdjacentToV(clique, v, graph)\n",
    "                used.append(v)\n",
    "                #print(\"plateau\", clique, level_candidates, max_deg_candidates)\n",
    "        iterations -= 1\n",
    "        #for i in used:\n",
    "            #penalties[i] += 1\n",
    "        not_clique = [i for i in vertices if i not in clique]\n",
    "        u = not_clique[random.randint(0, len(not_clique) - 1)]\n",
    "        clique.append(u)\n",
    "        clique = DropNonAdjacentToV(clique, u, graph)\n",
    "    return clique, selections#, penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PLS_random(graph, clique, selections, max_selections, iterations, vertices, clique_size, penalties):\n",
    "    used = []\n",
    "    candidates = rebuild_candidates(vertices, [], graph)\n",
    "    level_candidates = rebuild_level_neighbourhood(clique, graph, vertices, used)\n",
    "    \n",
    "    while iterations > 0 and selections < max_selections:\n",
    "        while len(candidates) > 0 or len(level_candidates) > 0:\n",
    "            candidates = rebuild_candidates(vertices, clique, graph)\n",
    "            while len(candidates) > 0:\n",
    "                candidates = rebuild_candidates(vertices, clique, graph)\n",
    "                if len(candidates) == 1:\n",
    "                    v = candidates[0]\n",
    "                else:\n",
    "                    v = candidates[random.randint(0, len(candidates) - 1)]\n",
    "                clique.append(v)\n",
    "                candidates = rebuild_candidates(vertices, clique, graph)\n",
    "\n",
    "            if len(clique) == clique_size:\n",
    "                return clique, selections#, penalties\n",
    "            selections += 1\n",
    "            #candidates = rebuild_candidates(vertices, [], graph)\n",
    "            level_candidates = rebuild_level_neighbourhood(clique, graph, vertices, used)\n",
    "            if len(level_candidates) > 0:\n",
    "                if len(level_candidates) == 1:\n",
    "                    v = level_candidates[0]\n",
    "                else:\n",
    "                    v = level_candidates[random.randint(0, len(level_candidates) - 1)]\n",
    "                clique.append(v)\n",
    "                clique = DropNonAdjacentToV(clique, v, graph)\n",
    "                used.append(v)\n",
    "        iterations -= 1\n",
    "        #for i in used:\n",
    "        #    penalties[i] += 1\n",
    "        not_clique = [i for i in vertices if i not in clique]\n",
    "        u = not_clique[random.randint(0, len(not_clique) - 1)]\n",
    "        clique.append(u)\n",
    "        clique = DropNonAdjacentToV(clique, u, graph)\n",
    "    return clique, selections#, penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PLS(graph, degrees, max_selections, clique_size):\n",
    "    selections = 0\n",
    "    vertices = list(i for i in range(len(graph)))\n",
    "    candidates = rebuild_candidates(vertices, [], graph)\n",
    "    penalties = [0] * len(vertices)\n",
    "    clique = [random.randint(0, len(vertices) - 1)]\n",
    "\n",
    "    while selections < max_selections:\n",
    "        clique, selections = PLS_random(graph, clique, selections, max_selections, 50, vertices, clique_size, penalties)\n",
    "        if len(clique) == clique_size:\n",
    "            #print(\"random\")\n",
    "            return clique\n",
    "        \n",
    "        clique, selections = PLS_penalties(graph, clique, selections, max_selections, 50, vertices, clique_size, penalties)\n",
    "        if len(clique) == clique_size:\n",
    "            #print(\"penalty\")\n",
    "            return clique\n",
    "        \n",
    "        clique, selections = PLS_degrees(graph, clique, degrees, selections, max_selections, 100, vertices, clique_size, penalties)\n",
    "        if len(clique) == clique_size:\n",
    "            #print(\"degrees\")\n",
    "            return clique\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_PLS(graph, graph_params, degrees, adj_list, max_iterations):    \n",
    "    start_time = time.time()\n",
    "    end_time = start_time + 50\n",
    "    clique = []\n",
    "    for i in range(int(graph_params[-2]), int(graph_params[-1])):\n",
    "        sampe = PLS(graph, degrees, max_iterations, i)\n",
    "        #AMTS(degrees, graph, adj_list, clique_size, search_depth, max_iters, graph_params)\n",
    "        #print(sampe)\n",
    "        if sampe == None:\n",
    "            i -= 1\n",
    "            break\n",
    "        else:\n",
    "            clique = sampe\n",
    "            end_time = time.time()\n",
    "            #print(clique, \"\\n\")\n",
    "            #for vertex in clique:\n",
    "                #print(vertex, adj_list[vertex])\n",
    "    return len(clique), end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CLS_Penalty(graph, degrees, adj_list, max_iterations, clique_size, vertices, penalties):\n",
    "    clique = [random.randint(0, len(graph) - 1)]\n",
    "    penalties = [0] * len(vertices)\n",
    "    used = []\n",
    "    iterations = 0\n",
    "    candidates = rebuild_candidates(vertices, clique, graph)\n",
    "    level_candidates = rebuild_level_neighbourhood(clique, graph, vertices, used)\n",
    "    while iterations < max_iterations:\n",
    "        while len(candidates) > 0 or len(level_candidates) > 0:\n",
    "            while len(candidates) > 0: \n",
    "                candidate_penalties = {k : penalties[k] for k in candidates}\n",
    "                min_penalties = min(list(candidate_penalties.values()))\n",
    "                min_pen_candidates = [i for i in candidates if penalties[i] == min_penalties]\n",
    "                if len(min_pen_candidates) == 1:\n",
    "                    v = min_pen_candidates[0]\n",
    "                else:\n",
    "                    v = min_pen_candidates[random.randint(0, len(min_pen_candidates) - 1)]\n",
    "                clique.append(v)\n",
    "                if len(clique) == clique_size:\n",
    "                    return True, clique\n",
    "                candidates = rebuild_candidates(vertices, clique, graph)\n",
    "                level_candidates = rebuild_level_neighbourhood(clique, graph, vertices, used)\n",
    "\n",
    "            if len(level_candidates) > 0:\n",
    "                candidate_penalties = {k : penalties[k] for k in level_candidates}\n",
    "                min_penalties = min(list(candidate_penalties.values()))\n",
    "                min_pen_candidates = [i for i in level_candidates if penalties[i] == min_penalties]\n",
    "                if len(min_pen_candidates) == 1:\n",
    "                    v = min_pen_candidates[0]\n",
    "                else:\n",
    "                    v = min_pen_candidates[random.randint(0, len(min_pen_candidates) - 1)]\n",
    "                clique.append(v)\n",
    "                clique = DropNonAdjacentToV(clique, v, graph)\n",
    "                used.append(v)\n",
    "                level_candidates = rebuild_level_neighbourhood(clique, graph, vertices, used)\n",
    "                candidates = rebuild_candidates(vertices, clique, graph)\n",
    "        iterations += 1    \n",
    "        for i in range(len(penalties)):\n",
    "            if penalties[i] > 0:\n",
    "                penalties[i] -= 1\n",
    "            if i in used:\n",
    "                penalties[i] += 2\n",
    "\n",
    "        not_clique = [i for i in vertices if i not in clique]\n",
    "        u = not_clique[random.randint(0, len(not_clique) - 1)]\n",
    "        clique.append(u)\n",
    "        clique = DropNonAdjacentToV(clique, u, graph)       \n",
    "        level_candidates = rebuild_level_neighbourhood(clique, graph, vertices, used)\n",
    "        candidates = rebuild_candidates(vertices, clique, graph)\n",
    "    return False, clique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CLS_Focus(graph, degrees, adj_list, max_iterations, clique_size, vertices, aim_degree):\n",
    "    clique = [random.randint(0, len(graph) - 1)]\n",
    "    used = []\n",
    "    iterations = 0\n",
    "    candidates = rebuild_candidates(vertices, clique, graph)\n",
    "    level_candidates = rebuild_level_neighbourhood(clique, graph, vertices, used)\n",
    "    while iterations < max_iterations:\n",
    "        while len(candidates) > 0 or len(level_candidates) > 0:\n",
    "            while len(candidates) > 0: \n",
    "                cand_degrees = {k : abs(v - aim_degree) for k, v in degrees.items() if k in candidates}\n",
    "                goal = min(list(cand_degrees.values()))\n",
    "                goal_deg_candidates = [i for i in list(cand_degrees.keys()) if cand_degrees[i] == goal]\n",
    "                if len(goal_deg_candidates) == 1:\n",
    "                    v = goal_deg_candidates[0]\n",
    "                else:\n",
    "                    v = goal_deg_candidates[random.randint(0, len(goal_deg_candidates) - 1)]\n",
    "                clique.append(v)\n",
    "                if len(clique) == clique_size:\n",
    "                    return clique\n",
    "                candidates = rebuild_candidates(vertices, clique, graph)\n",
    "                level_candidates = rebuild_level_neighbourhood(clique, graph, vertices, used)\n",
    "\n",
    "            if len(level_candidates) > 0:\n",
    "                level_cand_degrees = {k : abs(v - aim_degree) for k, v in degrees.items() if k in level_candidates}\n",
    "                goal = min(list(level_cand_degrees.values()))\n",
    "                goal_deg_candidates = [i for i in list(level_cand_degrees.keys()) if level_cand_degrees[i] == goal]\n",
    "                if len(goal_deg_candidates) == 1:\n",
    "                    v = goal_deg_candidates[0]\n",
    "                else:\n",
    "                    v = goal_deg_candidates[random.randint(0, len(goal_deg_candidates) - 1)]\n",
    "                clique.append(v)\n",
    "                clique = DropNonAdjacentToV(clique, v, graph)\n",
    "                used.append(v)\n",
    "                level_candidates = rebuild_level_neighbourhood(clique, graph, vertices, used)\n",
    "                candidates = rebuild_candidates(vertices, clique, graph)\n",
    "            #print(iterations)\n",
    "        iterations += 1    \n",
    "\n",
    "        not_clique = [i for i in vertices if i not in clique]\n",
    "        u = not_clique[random.randint(0, len(not_clique) - 1)]\n",
    "        clique.append(u)\n",
    "        clique = DropNonAdjacentToV(clique, u, graph) \n",
    "        level_candidates = rebuild_level_neighbourhood(clique, graph, vertices, used)\n",
    "        candidates = rebuild_candidates(vertices, clique, graph)      \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CLS_Level(graph, degrees, adj_list, max_iterations, clique_size, vertices, penalties):\n",
    "    clique = [random.randint(0, len(graph) - 1)]\n",
    "    #penalties = [0] * len(vertices)\n",
    "    used = []\n",
    "    iterations = 0\n",
    "    candidates = rebuild_candidates(vertices, clique, graph)\n",
    "    level_candidates = rebuild_level_neighbourhood(clique, graph, vertices, used)\n",
    "    while iterations < max_iterations:\n",
    "        while len(candidates) > 0 or len(level_candidates) > 0:\n",
    "            while len(candidates) > 0: \n",
    "                #print(\"Add\", iterations)\n",
    "                cand_degrees = {k : v for k, v in degrees.items() if k in candidates}\n",
    "                max_deg = max(list(cand_degrees.values()))\n",
    "                max_deg_candidates = [i for i in list(cand_degrees.keys()) if cand_degrees[i] == max_deg]\n",
    "                if len(max_deg_candidates) == 1:\n",
    "                    v = max_deg_candidates[0]\n",
    "                else:\n",
    "                    v = max_deg_candidates[random.randint(0, len(max_deg_candidates) - 1)]\n",
    "                clique.append(v)\n",
    "                if len(clique) == clique_size:\n",
    "                    return True, clique, penalties\n",
    "                candidates = rebuild_candidates(vertices, clique, graph)\n",
    "                level_candidates = rebuild_level_neighbourhood(clique, graph, vertices, used)\n",
    "\n",
    "            if len(level_candidates) > 0:\n",
    "                #print(\"Change\", iterations)\n",
    "                level_cand_degrees = {k : v for k, v in degrees.items() if k in level_candidates}\n",
    "                max_deg = max(list(level_cand_degrees.values()))\n",
    "                max_deg_candidates = [i for i in list(level_cand_degrees.keys()) if level_cand_degrees[i] == max_deg]\n",
    "                if len(max_deg_candidates) == 1:\n",
    "                    v = max_deg_candidates[0]\n",
    "                else:\n",
    "                    v = max_deg_candidates[random.randint(0, len(max_deg_candidates) - 1)]\n",
    "                clique.append(v)\n",
    "                clique = DropNonAdjacentToV(clique, v, graph)\n",
    "                used.append(v)\n",
    "                level_candidates = rebuild_level_neighbourhood(clique, graph, vertices, used)\n",
    "                candidates = rebuild_candidates(vertices, clique, graph)\n",
    "\n",
    "        iterations += 1   \n",
    "        #print(\"Drop\", iterations)\n",
    "        v_to_drop = clique[random.randint(0, len(clique) - 1)]\n",
    "        clique = [i for i in clique if i != v_to_drop]\n",
    "        level_candidates = rebuild_level_neighbourhood(clique, graph, vertices, used)\n",
    "        candidates = rebuild_candidates(vertices, clique, graph)\n",
    "        if len(candidates) == 0 and len(level_candidates) == 0:\n",
    "            not_clique = [i for i in vertices if i not in clique]\n",
    "            u = not_clique[random.randint(0, len(not_clique) - 1)]\n",
    "            clique.append(u)\n",
    "            clique = DropNonAdjacentToV(clique, u, graph)\n",
    "            level_candidates = rebuild_level_neighbourhood(clique, graph, vertices, used)\n",
    "            candidates = rebuild_candidates(vertices, clique, graph)\n",
    "\n",
    "        for i in range(len(penalties)):\n",
    "            if i in used:\n",
    "                penalties[i] += 1\n",
    "       \n",
    "    return False, clique, penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CLS_Greedy(graph, degrees, adj_list, max_iterations, clique_size, vertices):\n",
    "    clique = [random.randint(0, len(graph) - 1)]\n",
    "    penalties = [0] * len(vertices)\n",
    "    used = []\n",
    "    iterations = 0\n",
    "    candidates = rebuild_candidates(vertices, clique, graph)\n",
    "    level_candidates = rebuild_level_neighbourhood(clique, graph, vertices, used)\n",
    "    while iterations < max_iterations:\n",
    "        while len(candidates) > 0 or len(level_candidates) > 0:\n",
    "            while len(candidates) > 0: \n",
    "                cand_degrees = {k : v for k, v in degrees.items() if k in candidates}\n",
    "                max_deg = max(list(cand_degrees.values()))\n",
    "                max_deg_candidates = [i for i in list(cand_degrees.keys()) if cand_degrees[i] == max_deg]\n",
    "                if len(max_deg_candidates) == 1:\n",
    "                    v = max_deg_candidates[0]\n",
    "                else:\n",
    "                    v = max_deg_candidates[random.randint(0, len(max_deg_candidates) - 1)]\n",
    "                clique.append(v)\n",
    "                if len(clique) == clique_size:\n",
    "                    return True, clique, penalties\n",
    "                candidates = rebuild_candidates(vertices, clique, graph)\n",
    "                level_candidates = rebuild_level_neighbourhood(clique, graph, vertices, used)\n",
    "\n",
    "            if len(level_candidates) > 0:\n",
    "                level_cand_degrees = {k : v for k, v in degrees.items() if k in level_candidates}\n",
    "                max_deg = max(list(level_cand_degrees.values()))\n",
    "                max_deg_candidates = [i for i in list(level_cand_degrees.keys()) if level_cand_degrees[i] == max_deg]\n",
    "                if len(max_deg_candidates) == 1:\n",
    "                    v = max_deg_candidates[0]\n",
    "                else:\n",
    "                    v = max_deg_candidates[random.randint(0, len(max_deg_candidates) - 1)]\n",
    "                clique.append(v)\n",
    "                clique = DropNonAdjacentToV(clique, v, graph)\n",
    "                used.append(v)\n",
    "                level_candidates = rebuild_level_neighbourhood(clique, graph, vertices, used)\n",
    "                candidates = rebuild_candidates(vertices, clique, graph)\n",
    "        iterations += 1    \n",
    "        #print(iterations)\n",
    "        for i in range(len(penalties)):\n",
    "            if i in used:\n",
    "                penalties[i] += 1\n",
    "\n",
    "        not_clique = [i for i in vertices if i not in clique]\n",
    "        u = not_clique[random.randint(0, len(not_clique) - 1)]\n",
    "        clique.append(u)\n",
    "        clique = DropNonAdjacentToV(clique, u, graph)   \n",
    "        level_candidates = rebuild_level_neighbourhood(clique, graph, vertices, used)\n",
    "        candidates = rebuild_candidates(vertices, clique, graph)\n",
    " \n",
    "    return False, clique, penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CLS(graph, degrees, adj_list, max_iterations, clique_size):\n",
    "    vertices = [i for i in range(len(graph))]\n",
    "    #print(\"Greedy\")\n",
    "    success, clique, penalties = CLS_Greedy(graph, degrees, adj_list, max_iterations, clique_size, vertices)\n",
    "    if success:\n",
    "        return clique\n",
    "    else:\n",
    "        #print(\"Level\", clique)\n",
    "        success, clique, penalties = CLS_Level(graph, degrees, adj_list, max_iterations, clique_size, vertices, penalties)\n",
    "        if success:\n",
    "            return clique\n",
    "        else:\n",
    "            #print(\"Penalty\", clique)\n",
    "            success, clique = CLS_Penalty(graph, degrees, adj_list, max_iterations, clique_size, vertices, penalties)\n",
    "            if success:\n",
    "                return clique\n",
    "            else:\n",
    "                aim_degree = 0\n",
    "                for vertex in clique:\n",
    "                    aim_degree += degrees[vertex]\n",
    "                aim_degree // len(clique)\n",
    "                #print(\"Focus\", aim_degree)\n",
    "                clique = CLS_Focus(graph, degrees, adj_list, max_iterations, clique_size, vertices, aim_degree)\n",
    "\n",
    "    return clique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_CLS(graph, graph_params, degrees, adj_list, max_iterations):\n",
    "    start_time = time.time()\n",
    "    end_time = start_time + 50\n",
    "    clique = []\n",
    "    for i in range(int(graph_params[-2]), int(graph_params[-1])):\n",
    "        sampe = CLS(graph, degrees, adj_list, max_iterations, i)\n",
    "        #print(sampe)\n",
    "        if sampe == None:\n",
    "            i -= 1\n",
    "            break\n",
    "        else:\n",
    "            clique = sampe\n",
    "            end_time = time.time()\n",
    "            #print(clique, \"\\n\")\n",
    "            #for vertex in clique:\n",
    "                #print(vertex, adj_list[vertex])\n",
    "    return len(clique), end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SBTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_start(graph, vertices):\n",
    "    clique = []\n",
    "    candidates = rebuild_candidates(vertices, clique, graph)\n",
    "    while len(candidates) > 1:\n",
    "        clique.append(candidates[random.randint(0, len(candidates) - 1)])\n",
    "        candidates = rebuild_candidates(candidates, clique, graph)\n",
    "    if len(candidates) == 1:\n",
    "        clique.append(candidates[0])\n",
    "    return clique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_degrees(subset, clique, adj_list):\n",
    "    missing = {}\n",
    "    for vertex in subset:\n",
    "        missing_subclique = []\n",
    "        for elem in clique:\n",
    "            if elem not in adj_list[vertex]:\n",
    "                missing_subclique.append(elem)\n",
    "        missing[vertex] = [missing_subclique, len(missing_subclique)]\n",
    "    return missing         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expanding_degrees(subset, not_clique, adj_list, mapping_degrees):\n",
    "    degrees = {}\n",
    "    for vertex in subset:\n",
    "        counter = 0\n",
    "        for elem in adj_list[vertex]:\n",
    "            if elem in not_clique and mapping_degrees[elem][1] == 1:\n",
    "                counter += 1\n",
    "        degrees[vertex] = counter\n",
    "    return degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diversifying_degrees(graph, clique, not_clique):\n",
    "    degrees = {}\n",
    "    for vertex_1 in not_clique:\n",
    "        counter = 0\n",
    "        for vertex_2 in clique:\n",
    "            if graph[vertex_1][vertex_2] > 0:\n",
    "                counter += 1\n",
    "        degrees[vertex_1] = counter\n",
    "    return degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_level_candidates_SBTS(level_candidates, clique, current_expanding_degrees, graph):\n",
    "    result = []\n",
    "    for candidate in level_candidates:\n",
    "        drop = False\n",
    "        for vertex in clique:\n",
    "            if graph[candidate][vertex] > 0 and current_expanding_degrees[vertex] == 1:\n",
    "                drop = True\n",
    "                break\n",
    "        if drop == False:\n",
    "            result.append(candidate)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SBTS_Intensify(graph, adj_list, clique, candidates, level_candidates, vertices, taboo_list):\n",
    "    #print(\"Intensify\")\n",
    "    used = []\n",
    "    dropped = []\n",
    "    candidates = [i for i in rebuild_candidates(vertices, clique, graph) if taboo_list[i] == 0]\n",
    "    #print(\"candidates\", candidates)\n",
    "    while len(candidates) > 0:\n",
    "        if len(candidates) == 1:\n",
    "            v = candidates[0]\n",
    "        else:\n",
    "            v = candidates[random.randint(0, len(candidates) - 1)]\n",
    "        clique.append(v)\n",
    "        candidates = [i for i in rebuild_candidates(vertices, clique, graph) if taboo_list[i] == 0]\n",
    "        level_candidates = [i for i in rebuild_level_neighbourhood(clique, graph, vertices, used) if taboo_list[i] == 0]\n",
    "    #print(\"candidates\", candidates)\n",
    "    #print(\"level\", level_candidates)\n",
    "    if len(level_candidates) > 0:\n",
    "        not_clique = [i for i in vertices if i not in clique]\n",
    "        current_mapping_degrees = mapping_degrees(not_clique, clique, adj_list)\n",
    "        two_plus_candidates = [i for i in list(current_mapping_degrees.keys()) if i not in level_candidates]\n",
    "        current_expanding_degrees = expanding_degrees(vertices, not_clique, adj_list, current_mapping_degrees)\n",
    "        #print(\"two plus\", two_plus_candidates)\n",
    "        if len(level_candidates) > len(two_plus_candidates):\n",
    "            level_candidates = update_level_candidates_SBTS(level_candidates, clique, current_expanding_degrees, graph)\n",
    "            #print(\"changing candidates and degrees\", level_candidates, current_expanding_degrees)\n",
    "        current_expanding_degrees = {k : v for k, v in current_expanding_degrees.items() if k in level_candidates}\n",
    "        max_exp_degree = max(list(current_expanding_degrees.values()))\n",
    "        level_max_exp = [i for i in level_candidates if current_expanding_degrees[i] == max_exp_degree]\n",
    "        #print(\"max exp\", max_exp_degree, level_max_exp)\n",
    "        if len(level_max_exp) == 0:\n",
    "            clique = clique\n",
    "        else:\n",
    "            if len(level_max_exp) == 1:\n",
    "                v = level_max_exp[0]\n",
    "            else:\n",
    "                current_diversifying_degrees = diversifying_degrees(graph, clique, not_clique)\n",
    "                #print(current_diversifying_degrees)\n",
    "                current_diversifying_degrees = {k : v for k, v in current_diversifying_degrees.items() if k in level_max_exp}\n",
    "                #print(\"div degree\", current_diversifying_degrees, level_max_exp)\n",
    "                max_div_degree = max(list(current_diversifying_degrees.values()))\n",
    "                level_max_div = [i for i in level_max_exp if current_diversifying_degrees[i] == max_div_degree]\n",
    "                if len(level_max_div) == 1:\n",
    "                    v = level_max_div[0]\n",
    "                else:\n",
    "                    v = level_max_div[random.randint(0, len(level_max_div) - 1)]\n",
    "            old_clique = clique\n",
    "            #print(\"change\", v)\n",
    "            clique.append(v)\n",
    "            used.append(v)\n",
    "            clique = DropNonAdjacentToV(clique, v, graph)\n",
    "            dropped = [i for i in old_clique if i not in clique]\n",
    "        candidates = [i for i in rebuild_candidates(vertices, clique, graph) if i not in taboo_list]\n",
    "        level_candidates = [i for i in rebuild_level_neighbourhood(clique, graph, vertices, used) if taboo_list[i] == 0]\n",
    "    return clique, candidates, level_candidates, dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SBTS_diersify(graph, adj_list, clique, vertices, taboo_list):\n",
    "    #print(\"clique\", clique)\n",
    "    dropped = []\n",
    "    not_clique = [i for i in range(len(graph)) if i not in clique]\n",
    "    level_candidates = [i for i in rebuild_level_neighbourhood(clique, graph, vertices, []) if taboo_list[i] == 0]\n",
    "    not_clique = [i for i in vertices if i not in clique]\n",
    "    current_mapping_degrees = mapping_degrees(not_clique, clique, adj_list)\n",
    "    two_plus_candidates = [i for i in list(current_mapping_degrees.keys()) if i not in level_candidates and taboo_list[i] == 0]\n",
    "\n",
    "    # print(\"Taboo\", taboo_list)\n",
    "    # alt_level_candidates = rebuild_level_neighbourhood(clique, graph, vertices, [])\n",
    "    # alt_two_plus_candidates = [i for i in list(current_mapping_degrees.keys()) if i not in level_candidates and taboo_list[i] == 0]\n",
    "    # print(alt_level_candidates, alt_two_plus_candidates)\n",
    "    # print(level_candidates, two_plus_candidates)\n",
    "    three_plus_candidates = [i for i in list(current_mapping_degrees.keys()) if current_mapping_degrees[i][1] > 2 and taboo_list[i] == 0]\n",
    "\n",
    "    if len(level_candidates) > len(two_plus_candidates) and len(three_plus_candidates) > 0:\n",
    "        current_diversifying_degrees = diversifying_degrees(graph, clique, not_clique)\n",
    "        current_diversifying_degrees = {k : v for k, v in current_diversifying_degrees.items() if k in three_plus_candidates}\n",
    "        #print(level_candidates, three_plus_candidates, current_diversifying_degrees)\n",
    "        max_div_degree = max(list(current_diversifying_degrees.values()))\n",
    "        level_max_div = [i for i in three_plus_candidates if current_diversifying_degrees[i] == max_div_degree]\n",
    "        if len(level_max_div) == 1:\n",
    "            v = level_max_div[0]\n",
    "        else:\n",
    "            v = level_max_div[random.randint(0, len(level_max_div) - 1)]\n",
    "    else:\n",
    "        #print(\"two plus\", two_plus_candidates)\n",
    "        #print(\"level\", level_candidates)\n",
    "        if random.randint(0, 1) == 1 and len(two_plus_candidates) > 0:\n",
    "            two_candidates = [i for i in list(current_mapping_degrees.keys()) if current_mapping_degrees[i][1] == 2 and taboo_list[i] == 0]\n",
    "            if len(two_candidates) > 0:\n",
    "                current_diversifying_degrees = diversifying_degrees(graph, clique, not_clique)\n",
    "                current_diversifying_degrees = {k : v for k, v in current_diversifying_degrees.items() if k in two_candidates}\n",
    "                #print(\"two plus, two, current mapping degrees div degrees\", two_plus_candidates, two_candidates, current_mapping_degrees, current_diversifying_degrees)\n",
    "                max_div_degree = max(list(current_diversifying_degrees.values()))\n",
    "                level_max_div = [i for i in two_candidates if current_diversifying_degrees[i] == max_div_degree]\n",
    "                if len(level_max_div) == 1:\n",
    "                    v = level_max_div[0]\n",
    "                else:\n",
    "                    v = level_max_div[random.randint(0, len(level_max_div) - 1)]\n",
    "            else:\n",
    "                two_candidates = [i for i in list(current_mapping_degrees.keys()) if current_mapping_degrees[i][1] == 2]\n",
    "                if len(two_candidates) > 0:\n",
    "                    current_diversifying_degrees = diversifying_degrees(graph, clique, not_clique)\n",
    "                    current_diversifying_degrees = {k : v for k, v in current_diversifying_degrees.items() if k in two_candidates}\n",
    "                    #print(\"two plus, two, current mapping degrees div degrees\", two_plus_candidates, two_candidates, current_mapping_degrees, current_diversifying_degrees)\n",
    "                    max_div_degree = max(list(current_diversifying_degrees.values()))\n",
    "                    level_max_div = [i for i in two_candidates if current_diversifying_degrees[i] == max_div_degree]\n",
    "                    if len(level_max_div) == 1:\n",
    "                        v = level_max_div[0]\n",
    "                    else:\n",
    "                        v = level_max_div[random.randint(0, len(level_max_div) - 1)]\n",
    "        else:\n",
    "            if len(two_plus_candidates) == 1:\n",
    "                v = two_plus_candidates[0]\n",
    "            else:\n",
    "                if len(two_plus_candidates) > 0:\n",
    "                    v = two_plus_candidates[random.randint(0, len(two_plus_candidates) - 1)]\n",
    "                else:\n",
    "                    return clique, dropped\n",
    "    old_clique = clique\n",
    "    clique.append(v)\n",
    "    clique = DropNonAdjacentToV(clique, v, graph)\n",
    "    dropped = [i for i in old_clique if i not in clique]\n",
    "    return clique, dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_taboo_list(taboo_list, graph, vertices, clique, adj_list, moved):\n",
    "    if len(moved) == 1:\n",
    "        used = []\n",
    "        not_clique = [i for i in range(len(graph)) if i not in clique]\n",
    "        level_candidates = rebuild_level_neighbourhood(clique, graph, vertices, used)\n",
    "        not_clique = [i for i in vertices if i not in clique]\n",
    "        current_mapping_degrees = mapping_degrees(not_clique, clique, adj_list)\n",
    "        two_plus_candidates = [i for i in list(current_mapping_degrees.keys()) if i not in level_candidates]\n",
    "        if len(level_candidates) > len(two_plus_candidates):\n",
    "            taboo_list[moved[0]] = 10 + random.randint(0, len(level_candidates) - 1)\n",
    "        else:\n",
    "            taboo_list[moved[0]] = len(level_candidates)\n",
    "    else:\n",
    "        if len(moved) == 0:\n",
    "            for i in range(len(taboo_list)):\n",
    "                if taboo_list[i] > 0:\n",
    "                    taboo_list[i] -= 1\n",
    "        else:\n",
    "            for i in moved:\n",
    "                taboo_list[i] = 7\n",
    "    \n",
    "    return taboo_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SBTS(graph, degrees, adj_list, max_iterations):\n",
    "    start = time.time()\n",
    "    vertices = [i for i in range(len(graph))]\n",
    "    clique = random_start(graph, vertices)\n",
    "    best_clique = clique\n",
    "    end = time.time()\n",
    "    best_clique_size = len(clique)\n",
    "    taboo_list = [0] * len(graph)\n",
    "    iterations = 0\n",
    "    dropped = []\n",
    "    candidates = rebuild_candidates(vertices, clique, graph)\n",
    "    level_candidates = rebuild_level_neighbourhood(clique, graph, vertices, [])\n",
    "\n",
    "    while iterations < max_iterations:\n",
    "        #print(candidates, level_candidates)\n",
    "        #print(iterations, clique)\n",
    "        if len(candidates) > 0 or len(level_candidates) > 0:\n",
    "            clique, candidates, level_candidates, dropped = SBTS_Intensify(graph, adj_list, clique, candidates, level_candidates, vertices, taboo_list)\n",
    "            if len(clique) > best_clique_size:\n",
    "                end = time.time()\n",
    "                best_clique = clique\n",
    "                best_clique_size = len(clique)\n",
    "            update_taboo_list(taboo_list, graph, vertices, clique, adj_list, dropped)\n",
    "        else:\n",
    "            if len(clique) > 1:\n",
    "                clique, dropped = SBTS_diersify(graph, adj_list, clique, vertices, taboo_list)\n",
    "            else:\n",
    "                not_clique = [i for i in range(len(graph)) if i not in clique]\n",
    "                v = not_clique[random.randint(0, len(not_clique) - 1)]\n",
    "                dropped = clique\n",
    "                clique.append(v)\n",
    "                clique = DropNonAdjacentToV(clique, v, graph)\n",
    "            taboo_list = update_taboo_list(taboo_list, graph, vertices, clique, adj_list, dropped)\n",
    "        \n",
    "        update_taboo_list(taboo_list, graph, vertices, clique, adj_list, [])\n",
    "        iterations += 1\n",
    "\n",
    "    return best_clique, len(best_clique), end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_SBTS(graph, degrees, adj_list, max_iterations):\n",
    "    #start = time.time()\n",
    "    clique, clique_len, exec_time = SBTS(graph, degrees, adj_list, max_iterations)\n",
    "    #end = time.time()\n",
    "    return clique_len, exec_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ТЕСТЫ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all(graph, graph_params, degrees, adj_list, max_iters, n_times):\n",
    "    results = {}\n",
    "    best_clique_size, sum_time = 0, 0\n",
    "    for i in range(n_times):\n",
    "        clique_size, current_time = test_AMTS(graph, graph_params, degrees, adj_list, max_iters)\n",
    "        if clique_size > best_clique_size:\n",
    "            best_clique_size = clique_size\n",
    "        sum_time += current_time\n",
    "    results[0] = [best_clique_size, sum_time]\n",
    "\n",
    "    best_clique_size, sum_time = 0, 0\n",
    "    for i in range(n_times):\n",
    "        clique_size, current_time = test_DLS(graph, graph_params, degrees, adj_list, max_iters)\n",
    "        if clique_size > best_clique_size:\n",
    "            best_clique_size = clique_size\n",
    "        sum_time += current_time\n",
    "    results[1] = [best_clique_size, sum_time]\n",
    "\n",
    "    best_clique_size, sum_time = 0, 0\n",
    "    for i in range(n_times):\n",
    "        clique_size, current_time = test_PLS(graph, graph_params, degrees, adj_list, max_iters)\n",
    "        if clique_size > best_clique_size:\n",
    "            best_clique_size = clique_size\n",
    "        sum_time += current_time\n",
    "    results[2] = [best_clique_size, sum_time]\n",
    "\n",
    "    best_clique_size, sum_time = 0, 0\n",
    "    for i in range(n_times):\n",
    "        clique_size, current_time = test_CLS(graph, graph_params, degrees, adj_list, max_iters)\n",
    "        if clique_size > best_clique_size:\n",
    "            best_clique_size = clique_size\n",
    "        sum_time += current_time\n",
    "    results[3] = [best_clique_size, sum_time]\n",
    "\n",
    "    best_clique_size, sum_time = 0, 0\n",
    "    for i in range(n_times):\n",
    "        clique_size, current_time = test_SBTS(graph, degrees, adj_list, max_iters)\n",
    "        if clique_size > best_clique_size:\n",
    "            best_clique_size = clique_size\n",
    "        sum_time += current_time\n",
    "    results[4] = [best_clique_size, sum_time]\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_algorithm(result): \n",
    "    #result = {0: [21, 16.93840217590332], 1: [22, 0.9338009357452393], 2: [22, 0.33661413192749023], 3: [21, 0.22690391540527344], 4: [21, 11.393150568008423]}\n",
    "    clique_sizes = []\n",
    "    for key in list(result.keys()):\n",
    "        clique_sizes.append(result[key][0])\n",
    "    max_clique_size = max(clique_sizes)\n",
    "    best_solutions = [i for i in list(result.keys()) if result[i][0] == max_clique_size]\n",
    "    min_time = 100000\n",
    "    best_algorithm = -1\n",
    "    for solution in best_solutions:\n",
    "        if result[solution][1] < min_time:\n",
    "            min_time = result[solution][1]\n",
    "            best_algorithm = solution\n",
    "    return best_algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_on_graphs_series(filename_schematic, max_iterations,n_times):    \n",
    "    best = []\n",
    "    for k in range(10):\n",
    "        filename = filename_schematic + str(k) + \".csv\"\n",
    "        graph = np.genfromtxt(filename, delimiter = \" ,\")\n",
    "        parms_filename = \"paramsI\" + filename\n",
    "        graph_params = np.genfromtxt(parms_filename, delimiter = \" ,\")\n",
    "        graph, degrees, adj_list = get_graph_lists(graph)\n",
    "        results = test_all(graph, graph_params, degrees, adj_list, max_iterations, n_times)\n",
    "        best_algorithm = find_best_algorithm(results)\n",
    "        best.append(best_algorithm)\n",
    "\n",
    "    results_filename = \"resultsI\" + filename\n",
    "    print(best, results_filename)\n",
    "    best = np.array(best)\n",
    "    np.savetxt(results_filename, best, delimiter = \" ,\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1, 2, 1, 1, 3, 2, 1, 1, 3] resultsIgraphI500I60I9.csv\n"
     ]
    }
   ],
   "source": [
    "filename = \"graphI500I\"\n",
    "for i in range(60, 65, 5):\n",
    "    execute_on_graphs_series(filename + str(i) + \"I\", 250, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"graphI150I95I1.csv\"\n",
    "graph = np.genfromtxt(filename, delimiter = \" ,\")\n",
    "\n",
    "graph_params = np.genfromtxt(\"paramsI\" + filename, delimiter = \" ,\")\n",
    "graph, degrees, adj_list = get_graph_lists(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [21, 52.904942750930786], 1: [22, 3.300570487976074], 2: [22, 2.7230067253112793], 3: [22, 6.838778972625732], 4: [23, 7.916337966918945]} 2\n"
     ]
    }
   ],
   "source": [
    "results = test_all(graph, graph_params, degrees, adj_list, 500, 5)\n",
    "print(results, find_best_algorithm(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMTS (50, 20.40083885192871)\n",
      "DLS (52, 7.745387077331543)\n",
      "PLS (51, 7.373023986816406)\n",
      "CLS (51, 5.665826082229614)\n",
      "SBTS (52, 10.713024854660034)\n"
     ]
    }
   ],
   "source": [
    "print(\"AMTS\", test_AMTS(graph, graph_params, degrees, adj_list, 750))\n",
    "print(\"DLS\", test_DLS(graph, graph_params, degrees, adj_list, 750))\n",
    "print(\"PLS\", test_PLS(graph, graph_params, degrees, adj_list, 750))\n",
    "print(\"CLS\", test_CLS(graph, graph_params, degrees, adj_list, 750))\n",
    "print(\"SBTS\", test_SBTS(graph, degrees, adj_list, 750))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "СРАВНЕНИЕ НЕЙРОННЫХ МОДЕЛЕЙ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import coo_matrix\n",
    "import fast_matrix_market as fmm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "\n",
    "params = [[150, 0.95], [200, 0.95], [300, 0.85], [400, 0.6], [500, 0.6], [1000, 0.4], [1500, 0.4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_lists_obj(graph): # Преобразование графа в список и получение списков смежности и степеней для вершин\n",
    "    graph = list(graph)\n",
    "    for i in range(len(graph)):\n",
    "        graph[i] = list(graph[i])\n",
    "\n",
    "    adj_list = {}\n",
    "    degrees = {}\n",
    "    for i in range(len(graph)):\n",
    "        temp = []\n",
    "        degree = 0\n",
    "        for j in range(len(graph)):\n",
    "            if graph[i][j] == 1.0:\n",
    "                degree += 1\n",
    "                temp.append(j)\n",
    "        adj_list[i] = temp\n",
    "        degrees[i] = degree\n",
    "\n",
    "    degrees = {k: v for k, v in sorted(degrees.items(), key=lambda item: item[1], reverse = True)}\n",
    "    return graph, degrees, adj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_search(degrees, graph): #Жадный поиск\n",
    "    candidates = list(degrees.keys())\n",
    "    clique = [candidates[0]]\n",
    "\n",
    "    while True:\n",
    "        candidate_index = 0 \n",
    "        to_drop = []\n",
    "\n",
    "        #print(clique, candidates)\n",
    "\n",
    "        for candidate in candidates: #Перестроение списка кандидатов\n",
    "            for vertex in clique:\n",
    "                if graph[vertex][candidate] == 0:\n",
    "                    to_drop.append(candidate_index)\n",
    "                    break\n",
    "                \n",
    "            candidate_index += 1\n",
    "\n",
    "        candidates = [i for j, i in enumerate(candidates) if j not in to_drop]\n",
    "        \n",
    "        if len(candidates) == 0: #Если кандидаты ещё есть - добавление в клику лучшего, иначе завершение программы\n",
    "            break\n",
    "        clique.append(candidates[0])\n",
    "\n",
    "    return clique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_coloring(adj_list): #Жадное окрашивание\n",
    "    vertices = sorted(list(adj_list.keys()))\n",
    "    colour_graph = {}\n",
    "\n",
    "    for vertex in vertices:\n",
    "        unused_colours = len(vertices) * [True] #Список неиспользованных цветов\n",
    "\n",
    "        for neighbor in adj_list[vertex]: #Отмечаются все занятые соседями цвета\n",
    "            if neighbor in colour_graph:\n",
    "                colour = colour_graph[neighbor] \n",
    "                unused_colours[colour] = False\n",
    "\n",
    "        for colour, unused in enumerate(unused_colours): #Вершине присваивается первый незанятый цвет\n",
    "            if unused:\n",
    "                colour_graph[vertex] = colour\n",
    "                break\n",
    "\n",
    "    return colour_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_params(graph):\n",
    "    graph, degrees, adj_list = get_graph_lists_obj(graph)\n",
    "    greedy_clique = greedy_search(degrees, graph)\n",
    "    colored = greedy_coloring(adj_list)\n",
    "\n",
    "    gs_res = len(greedy_clique)\n",
    "\n",
    "    gc_res = len(np.unique(list(colored.values())))\n",
    "\n",
    "    vertex_num = len(graph)\n",
    "\n",
    "    edges_num = 0\n",
    "    degrees_sum = []\n",
    "    for i in range(vertex_num):\n",
    "        for j in range(i, vertex_num):\n",
    "            if graph[i][j] > 0:\n",
    "                edges_num += 1\n",
    "                degrees_sum.append(degrees[i] + degrees[j])\n",
    "    density = edges_num / vertex_num\n",
    "\n",
    "    degrees_list = list(degrees.values())\n",
    "    min_deg = min(degrees_list)\n",
    "    max_deg = max(degrees_list)\n",
    "    mean_deg = np.mean(degrees_list)\n",
    "    std_deg = np.std(degrees_list)\n",
    "\n",
    "    deg_sum_max = max(degrees_sum)\n",
    "    deg_sum_min = min(degrees_sum)\n",
    "    deg_sum_mean = np.mean(degrees_sum)\n",
    "    deg_sum_std = np.std(degrees_sum)\n",
    "    \n",
    "    graph_params = []\n",
    "    graph_params.append(vertex_num)\n",
    "    graph_params.append(edges_num)\n",
    "    graph_params.append(density)\n",
    "    graph_params.append(min_deg)\n",
    "    graph_params.append(max_deg)\n",
    "    graph_params.append(mean_deg)\n",
    "    graph_params.append(std_deg)\n",
    "    graph_params.append(deg_sum_min)\n",
    "    graph_params.append(deg_sum_max)\n",
    "    graph_params.append(deg_sum_mean)\n",
    "    graph_params.append(deg_sum_std)\n",
    "    graph_params.append(gs_res)\n",
    "    graph_params.append(gc_res)\n",
    "\n",
    "    return graph_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "answers = []\n",
    "\n",
    "for i in range(len(params)):\n",
    "    limit = int(params[i][1] // 0.05)\n",
    "    for j in range(limit + 1):\n",
    "        possibility = min((j + 1) * 0.05, params[i][1])\n",
    "        filename = \"graphI\" + str(params[i][0]) + \"I\" + str(int(possibility * 100)) + \"I\"\n",
    "        serie_results = list(np.genfromtxt(\"resultsI\" + filename + \"9.csv\", delimiter = \" ,\"))\n",
    "        answers += serie_results\n",
    "        for k in range(10):\n",
    "            graph_params = list(np.genfromtxt(\"paramsI\" + filename + str(k) + \".csv\", delimiter = \" ,\"))\n",
    "            features.append(graph_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_regr = LogisticRegression(solver='lbfgs', max_iter=10000, multi_class='ovr')\n",
    "log_regr.fit(features, answers)\n",
    "lin_regr = LinearRegression()\n",
    "lin_regr.fit(features, answers)\n",
    "svc = svm.SVC()\n",
    "svc.fit(features, answers)\n",
    "bayes = GaussianNB()\n",
    "bayes.fit(features, answers)\n",
    "trees = tree.DecisionTreeClassifier()\n",
    "trees.fit(features, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_on_dimacs_graph(filename):\n",
    "    (data, (rows, cols)), shape = fmm.read_coo(filename)\n",
    "    graph = coo_matrix((data, (rows, cols)), shape).toarray()\n",
    "    graph_params = get_graph_params(graph)\n",
    "    log_res = int(log_regr.predict(np.array(graph_params).reshape(1, -1)))\n",
    "    lin_res = int(lin_regr.predict(np.array(graph_params).reshape(1, -1)))\n",
    "    svc_res = int(svc.predict(np.array(graph_params).reshape(1, -1)))\n",
    "    bayes_res = int(bayes.predict(np.array(graph_params).reshape(1, -1)))\n",
    "    trees_res = int(trees.predict(np.array(graph_params).reshape(1, -1)))\n",
    "\n",
    "    return {\"logical\" : log_res, \"linear\": lin_res, \"vector\" : svc_res, \"bayes\" : bayes_res, \"tree\" : trees_res}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all_on_dimacs(filename):    \n",
    "    (data, (rows, cols)), shape = fmm.read_coo(filename)\n",
    "    graph = coo_matrix((data, (rows, cols)), shape).toarray()\n",
    "    graph_params = get_graph_params(graph)\n",
    "    graph, degrees, adj_list = get_graph_lists_obj(graph)\n",
    "    results = test_all(graph, graph_params, degrees, adj_list, 500, 5)\n",
    "    print(results, find_best_algorithm(results))\n",
    "    return results, find_best_algorithm(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_classificators(filename):\n",
    "    results = pred_on_dimacs_graph(filename)\n",
    "    print(results)\n",
    "    test_all_on_dimacs(filename)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimacs = [\"brock200-2.mtx\", \"brock200-4.mtx\", \"brock400-1.mtx\", \"brock400-3.mtx\", \"brock800-1.mtx\", \"brock800-3.mtx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{'logical': 4, 'linear': 3, 'vector': 4, 'bayes': 4, 'tree': 4}\n",
      "{0: [9, 7.085291862487793], 1: [11, 2.380017042160034], 2: [11, 1.355820655822754], 3: [12, 34.45299768447876], 4: [11, 2.3343305587768555]} 3\n",
      "\n",
      "\n",
      "{'logical': 4, 'linear': 3, 'vector': 4, 'bayes': 4, 'tree': 1}\n",
      "{0: [14, 29.793453216552734], 1: [16, 2.1580920219421387], 2: [16, 6.24228048324585], 3: [16, 5.718635559082031], 4: [16, 1.7407643795013428]} 4\n",
      "\n",
      "\n",
      "{'logical': 4, 'linear': 3, 'vector': 4, 'bayes': 1, 'tree': 3}\n",
      "{0: [21, 169.12297177314758], 1: [23, 12.571671962738037], 2: [23, 12.900123596191406], 3: [24, 188.0652039051056], 4: [24, 90.73415350914001]} 4\n",
      "\n",
      "\n",
      "{'logical': 4, 'linear': 3, 'vector': 4, 'bayes': 1, 'tree': 3}\n",
      "{0: [21, 167.46181416511536], 1: [23, 12.697833776473999], 2: [24, 28.29514789581299], 3: [24, 303.1239285469055], 4: [23, 24.436346292495728]} 2\n",
      "\n",
      "\n",
      "{'logical': 3, 'linear': 3, 'vector': 4, 'bayes': 3, 'tree': 4}\n",
      "{0: [18, 327.744056224823], 1: [19, 28.846678495407104], 2: [20, 66.08156681060791], 3: [20, 398.67057943344116], 4: [21, 165.87991905212402]} 4\n",
      "\n",
      "\n",
      "{'logical': 3, 'linear': 3, 'vector': 4, 'bayes': 3, 'tree': 4}\n",
      "{0: [17, 169.8901493549347], 1: [20, 59.46459603309631], 2: [20, 85.38803839683533], 3: [19, 216.75721096992493], 4: [19, 172.80805134773254]} 1\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "for graph in dimacs:\n",
    "    print(\"\\n\")\n",
    "    compare_classificators(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{'logical': 4, 'linear': 3, 'vector': 4, 'bayes': 4, 'tree': 4}\n",
      "{0: [19, 74.1595025062561], 1: [20, 4.575829029083252], 2: [21, 7.86239767074585], 3: [20, 17.202847242355347], 4: [20, 5.908117294311523]} 2\n",
      "\n",
      "\n",
      "{'logical': 4, 'linear': 3, 'vector': 4, 'bayes': 4, 'tree': 1}\n",
      "{0: [13, 18.409181594848633], 1: [13, 1.393322467803955], 2: [14, 3.280411720275879], 3: [14, 22.94440984725952], 4: [15, 1.3860337734222412]} 4\n",
      "\n",
      "\n",
      "{'logical': 4, 'linear': 2, 'vector': 4, 'bayes': 1, 'tree': 3}\n",
      "{0: [21, 229.0097155570984], 1: [23, 20.570472955703735], 2: [24, 30.63174295425415], 3: [24, 107.91820025444031], 4: [24, 36.56958556175232]} 2\n",
      "\n",
      "\n",
      "{'logical': 2, 'linear': 3, 'vector': 4, 'bayes': 1, 'tree': 3}\n",
      "{0: [20, 114.2393217086792], 1: [23, 23.644347429275513], 2: [24, 29.020169734954834], 3: [24, 327.62545800209045], 4: [25, 100.87111496925354]} 4\n",
      "\n",
      "\n",
      "{'logical': 3, 'linear': 2, 'vector': 4, 'bayes': 3, 'tree': 4}\n",
      "{0: [18, 701.0199453830719], 1: [20, 40.06808161735535], 2: [19, 44.73257899284363], 3: [21, 1092.1879181861877], 4: [20, 103.3860433101654]} 3\n",
      "\n",
      "\n",
      "{'logical': 3, 'linear': 3, 'vector': 4, 'bayes': 3, 'tree': 4}\n",
      "{0: [17, 257.4561343193054], 1: [20, 89.42653894424438], 2: [19, 56.59480667114258], 3: [20, 1044.3015966415405], 4: [20, 182.23817420005798]} 1\n"
     ]
    }
   ],
   "source": [
    "dimacs_2 = [\"brock200-1.mtx\", \"brock200-3.mtx\", \"brock400-2.mtx\", \"brock400-4.mtx\", \"brock800-2.mtx\", \"brock800-4.mtx\"]\n",
    "for graph in dimacs_2:\n",
    "    print(\"\\n\")\n",
    "    compare_classificators(graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
